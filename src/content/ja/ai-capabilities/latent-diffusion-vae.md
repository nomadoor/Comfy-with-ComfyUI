---
layout: page.njk
lang: ja
section: ai-capabilities
slug: latent-diffusion-vae
navId: latent-diffusion-vae
title: "Latent Diffusion ModelとVAE"
summary: "潜在空間とVAEの役割"
permalink: "/{{ lang }}/{{ section }}/{{ slug }}/"
hero:
  image: ""
---

## Latent Diffusion Modelとは？

![](https://gyazo.com/22d5f654c3c598feb046cf71d4d8d4aa){gyazo=image}

**Latent Diffusion Model** は、画像生成AIを自宅PCでも動かせるようにした一番大きな工夫のひとつです。

普通の画像（ピクセル）のまま拡散処理をすると、画素数が多すぎて計算が重くなります。  
そこで、一度画像を **「潜在空間（latent）」と呼ばれる圧縮表現** に変換してから、そこでノイズを足したり減らしたりします。

例としてStable Diffusion 1.5では、`512×512×3`の画像を`64×64×4`の「潜在画像」に圧縮して扱います。

縦横が1/8になるので、画素数は1/64です。  
この「少ない画素数の世界で拡散をやる」おかげで、ご家庭でも現実的な速度で画像生成ができるようになったのです！

---

## なぜ潜在空間で処理するのか

### 1. 計算量とVRAMの節約

512×512の画像を扱う場合、512×512個のドット一つ一つに対して何色か？を計算しなければいけません。

圧縮した潜在表現なら64×64になるので、ずっと計算量を減らすことができます。

### 2. 意味のまとまりを持った表現で処理できる

潜在空間では、ピクセル単位の細かいノイズではなく、「物体の形」「質感」「色の傾向」といった高レベルな特徴が圧縮されています。

また、潜在表現は「形が不安定な粘土」のようなものです。ピクセル画像同士を混ぜることに特に意味はありませんが、潜在画像の状態で組み合わせると、自然な合成を行えたりします。

---

## VAEとは？

**VAE（Variational Autoencoder）** は、画像を潜在空間へ変換したり、逆に戻したりする変換器です。

- **Encoder**：画像 → 潜在画像 に変換
- **Decoder**：潜在画像 → 画像 に戻す

生成の流れは次のようになります。

- 1. 拡散モデルは、潜在画像のノイズからスタート
- 2. U-Net（拡散モデル本体）が、潜在画像上でノイズを少しずつ減らす
- 3. 最後にVAEのDecoderを通して、「潜在画像 → ふつうの画像」に変換

img2imgやinpaintなど、画像を入力にする場合は、画像をEncoderで潜在表現に変換してから、同じことをします。

---

## VAEは非可逆圧縮

VAEは **非可逆圧縮** です。

画像を潜在空間に変換して、また画像に戻しても、**完全には元通りにはなりません**。  
わずかにボケたり、色味やコントラストが変わったりします。

![](https://gyazo.com/8741de326b196b666b2d0617502f3814){gyazo=image}

拡散モデルを使わず、単純に画像を VAE でエンコードして、同じ VAE でデコードしてみると、わずかに劣化しているのが分かるはずです。  
この「少しだけ劣化する代わりに、軽く扱えるようにする」というトレードオフが、潜在表現の特徴です。

---

## どのVAEを使えばいいか？

モデルによって使われている潜在表現が違い、それを作るためのVAEも違います。

基本的には、**モデルに合ったVAEを使わないといけません。**

間違ったVAEを使うと、色が変になったり、ノイズが乗ったりした画像ができてしまいます。